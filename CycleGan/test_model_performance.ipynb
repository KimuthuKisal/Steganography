{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator_model import Generator \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_checkpoint(checkpoint_file:str, model, device):\n",
    "    print(\"Loading checkpoint \", checkpoint_file)\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((256, 256)), \n",
    "        transforms.ToTensor(),          \n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = preprocess(image).unsqueeze(0)  \n",
    "    return image_tensor, image\n",
    "\n",
    "def postprocess_output(output_tensor):\n",
    "    output_image = transforms.ToPILImage()(output_tensor.squeeze().cpu())  \n",
    "    return output_image\n",
    "\n",
    "def run_inference(generator_model, input_image_tensor, device):\n",
    "    input_image_tensor = input_image_tensor.to(device)\n",
    "    with torch.no_grad(): \n",
    "        output = generator_model(input_image_tensor)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "input_image_tensor, original_image = preprocess_image('./TestImages/(6).JPEG')\n",
    "\n",
    "generator_T_model = Generator(3)\n",
    "generator_S_model = Generator(3)\n",
    "load_checkpoint(\"./TestModels/200_gen_t.pth.tar\", generator_T_model, device)\n",
    "load_checkpoint(\"./TestModels/200_gen_s.pth.tar\", generator_S_model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_image = generator_T_model(input_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypted_image_tensor = encrypted_image.detach().cpu()\n",
    "encrypted_image = postprocess_output(encrypted_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image = generator_S_model(encrypted_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_image_tensor = reconstructed_image.detach().cpu()\n",
    "reconstructed_image = postprocess_output(reconstructed_image_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))  # Create subplots with 1 row and 2 columns\n",
    "\n",
    "# Display the original input image\n",
    "ax[0].imshow(original_image)\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis('off')  # Hide axes\n",
    "\n",
    "# Display the generated output image\n",
    "ax[1].imshow(encrypted_image)\n",
    "ax[1].set_title(\"Encrypted Image\")\n",
    "ax[1].axis('off')  # Hide axes\n",
    "\n",
    "ax[2].imshow(reconstructed_image)\n",
    "ax[2].set_title(\"Reconstructed Image\")\n",
    "ax[2].axis('off')  # Hide axes\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from generator_model import Generator \n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gen_t_path = \"./TestModels/200_gen_t.pth.tar\"\n",
    "gen_s_path = \"./TestModels/200_gen_s.pth.tar\"\n",
    "test_images_dir = './TestImages'\n",
    "\n",
    "def load_checkpoint(checkpoint_file:str, model, device):\n",
    "    print(\"Loading checkpoint \", checkpoint_file)\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((256, 256)), \n",
    "        transforms.ToTensor(),          \n",
    "    ])\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = preprocess(image).unsqueeze(0)  \n",
    "    return image_tensor, image\n",
    "\n",
    "def postprocess_output(output_tensor):\n",
    "    output_image = transforms.ToPILImage()(output_tensor.squeeze().cpu())  \n",
    "    return output_image\n",
    "\n",
    "def run_inference(generator_model, input_image_tensor, device):\n",
    "    input_image_tensor = input_image_tensor.to(device)\n",
    "    with torch.no_grad(): \n",
    "        output = generator_model(input_image_tensor)\n",
    "    return output\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "generator_T_model = Generator(3)\n",
    "generator_S_model = Generator(3)\n",
    "load_checkpoint(gen_t_path, generator_T_model, device)\n",
    "load_checkpoint(gen_s_path, generator_S_model, device)\n",
    "\n",
    "for filename in os.listdir(test_images_dir):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png', 'JPEG', 'JPG', '.PNG')):  # Filter for image files\n",
    "        image_path = os.path.join(test_images_dir, filename)\n",
    "        \n",
    "        # Preprocess input image\n",
    "        input_image_tensor, original_image = preprocess_image(image_path)\n",
    "\n",
    "        # Run inference on the input image using both models\n",
    "        encrypted_image = generator_T_model(input_image_tensor)\n",
    "        encrypted_image_tensor = encrypted_image.detach().cpu()\n",
    "        encrypted_image = postprocess_output(encrypted_image_tensor)\n",
    "        \n",
    "        reconstructed_image = generator_S_model(encrypted_image_tensor)\n",
    "        reconstructed_image_tensor = reconstructed_image.detach().cpu()\n",
    "        reconstructed_image = postprocess_output(reconstructed_image_tensor)\n",
    "\n",
    "        # Display the original, encrypted, and reconstructed images\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(10, 5))  # Create subplots with 1 row and 3 columns\n",
    "        \n",
    "        # Display the original input image\n",
    "        ax[0].imshow(original_image)\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis('off')  # Hide axes\n",
    "\n",
    "        # Display the encrypted image\n",
    "        ax[1].imshow(encrypted_image)\n",
    "        ax[1].set_title(\"Encrypted Image\")\n",
    "        ax[1].axis('off')  # Hide axes\n",
    "\n",
    "        # Display the reconstructed image\n",
    "        ax[2].imshow(reconstructed_image)\n",
    "        ax[2].set_title(\"Reconstructed Image\")\n",
    "        ax[2].axis('off')  # Hide axes\n",
    "\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
